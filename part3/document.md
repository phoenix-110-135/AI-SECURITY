

# مستند عملکرد توابع ه Safe Agent

این مستند توضیح می‌دهد هر تابع در  **Safe Agent** چه کاری انجام می‌دهد و چگونه ورودی‌ها را پردازش و خروجی تولید می‌کند. هدف اصلی، **حفاظت از مدل زبانی بزرگ (LLM) در برابر محتوای حساس، ناامن یا سوءاستفاده‌پذیر** است.

---

## 1. تابع `precheck(user_input: str)`

**هدف:**  
این تابع ورودی کاربر را بررسی می‌کند تا مشخص شود امن است یا خیر و اطلاعات موضوعی آن را برمی‌گرداند. از مدل نگهبان **Qwen2.5** برای این کار استفاده می‌شود.

**ورودی:**  
- `user_input` (رشته): متن پرسش یا دستور کاربر.

**خروجی:**  
یک دیکشنری با این اطلاعات:  
- `safety`: `"safe"` یا `"unsafe"`  
- `topic_label`: برچسب موضوعی، مثل `GENERAL`، `ILLEGAL_ACTIVITY`، `MEDICAL_RISK` و غیره  
- `reason`: توضیح کوتاه برای ثبت و مستندسازی

**نحوه عملکرد:**  
1. تعریف لیست برچسب‌های مجاز  
2. آماده کردن پرامپت سیستم برای مدل نگهبان، با تاکید روی تولید فقط JSON معتبر  
3. آماده‌سازی پیام‌ها برای مدل  
4. تبدیل ورودی به توکن‌ها و آماده‌سازی برای مدل Qwen2.5  
5. گرفتن خروجی از مدل  
6. استخراج JSON از متن خروجی  
7. اعمال قوانین fallback در صورت نامعتبر بودن یا خطا  
8. اطمینان از اینکه مقادیر نهایی معتبر و استاندارد هستند

**نکات امنیتی:**  
- جلوگیری از تولید متن اضافی یا اطلاعات داخلی  
- پوشش سناریوهای خاص: Base64، zero-width، JAILBREAK، SELF_HARM  
- همیشه خروجی JSON استاندارد تولید می‌شود حتی در شرایط خطا

---

## 2. تابع `get_llm_response(question: str, system_instructions: str = None, timeout: float = 60.0)`

**هدف:**  
ارسال ورودی امن به مدل اصلی و دریافت پاسخ.

**ورودی‌ها:**  
- `question` (رشته): پرسش یا دستور کاربر  
- `system_instructions` (رشته اختیاری): راهنمایی سبک برای مدل  
- `timeout` (عدد اختیاری): حداکثر زمان انتظار برای پاسخ

**خروجی:**  
- پاسخ مدل (رشته) یا پیام خطا در صورت بروز مشکل

**نحوه عملکرد:**  
1. ساخت URL API مدل  
2. تعیین هدرها شامل Authorization  
3. آماده‌سازی پیام‌ها با نقش کاربر و سیستم  
4. ارسال درخواست POST  
5. مدیریت خطاهای HTTP و Exception  
6. بازگرداندن پاسخ مدل یا پیام خطا

**ویژگی‌ها:**  
- امکان هدایت مدل با system instructions  
- مدیریت امن زمان و خطاها  
- جداسازی مسیرهای امن و ناامن

---

## 3. تابع `org_llm(user_input: str)`

**هدف:**  
تصمیم‌گیری درباره مسیر امن برای پاسخ: ارسال به LLM اصلی یا تولید پیام امتناع.

**ورودی:**  
- `user_input` (رشته): متن پرسش یا دستور

**خروجی:**  
دیکشنری شامل:  
- `safety`: `"safe"` یا `"unsafe"`  
- `topic_label`: برچسب موضوعی تشخیص داده شده  
- `response`: متن پاسخ یا پیام امتناع

**نحوه عملکرد:**  
1. فراخوانی `precheck` برای بررسی ایمنی ورودی  
2. استخراج وضعیت و برچسب موضوع  
3. اگر ورودی امن باشد:  
   - ساختن یک system hint سبک  
   - ارسال به LLM اصلی و دریافت پاسخ  
4. اگر ناامن باشد:  
   - آماده کردن دستورالعمل برای پیام امتناع کوتاه، محترمانه و امن  
   - تولید پاسخ بدون افشای جزئیات خطرناک

**نکات امنیتی:**  
- جلوگیری از ارسال محتوای ناامن به مدل اصلی  
- تولید پیام‌های امن و خلاقانه برای مسیرهای ناامن  
- ثبت و قابل بررسی بودن تصمیم‌ها

---

## جمع‌بندی

این سه تابع با هم یک **زنجیره امن و قابل اعتماد** ایجاد می‌کنند:  
1. بررسی و تشخیص ایمنی ورودی  
2. ارسال ورودی امن به مدل یا تولید پیام امتناع  
3. بازگرداندن پاسخ استاندارد به کاربر

ویژگی‌های کلیدی:  
- محافظت در برابر jailbreak و prompt injection  
- تولید JSON استاندارد و قابل بررسی  
- تفکیک مسیرهای امن و ناامن  
- قابلیت توسعه و نگهداری آسان










